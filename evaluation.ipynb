{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2369062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['episode000', 'episode001', 'episode002', 'episode003', 'episode004', 'episode005', 'episode006', 'episode007', 'episode008', 'episode009', 'episode010', 'episode011', 'episode012', 'episode013', 'episode014', 'episode015', 'episode016', 'episode017', 'episode018', 'episode019', 'episode020', 'episode021', 'episode022', 'episode023', 'episode024', 'episode025', 'episode026', 'episode027', 'episode028', 'episode029', 'episode030', 'episode031', 'episode032', 'episode033', 'episode034', 'episode035', 'episode036', 'episode037', 'episode038', 'episode039', 'episode040', 'episode041', 'episode042', 'episode043', 'episode044', 'episode045', 'episode046', 'episode047', 'episode048', 'episode049', 'episode050', 'episode051', 'episode052', 'episode053', 'episode054', 'episode055', 'episode056', 'episode057', 'episode058', 'episode059', 'episode060', 'episode061', 'episode062', 'episode063', 'episode064', 'episode065', 'episode066', 'episode067', 'episode068', 'episode069', 'episode070', 'episode071', 'episode072', 'episode073', 'episode074', 'episode075', 'episode076', 'episode077', 'episode078', 'episode079', 'episode080', 'episode081', 'episode082', 'episode083', 'episode084', 'episode085', 'episode086', 'episode087', 'episode088', 'episode089', 'episode090', 'episode091', 'episode092', 'episode093', 'episode094', 'episode095', 'episode096', 'episode097', 'episode098', 'episode099', 'episode100', 'episode101', 'episode102', 'episode103', 'episode104', 'episode105', 'episode106', 'episode107', 'episode108']\n",
      "(318, 11)\n",
      "[ 3.0280012e-01 -5.6915589e-02  1.1275961e+00  6.6436871e-07\n",
      "  9.9999994e-01 -3.4745012e-06  3.8833377e-06  1.0000000e+00\n",
      "  4.2091480e-01  2.2506712e-02  5.0053000e-01]\n",
      "[ 3.0280003e-01 -5.6915559e-02  1.1275964e+00  7.0907276e-07\n",
      "  9.9999988e-01 -3.2411465e-06  3.8638618e-06  1.0000000e+00\n",
      "  4.2091480e-01  2.2506712e-02  5.0053000e-01]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.load(\"/AILAB-summer-school-2025/dataset_all.npz\")\n",
    "print(data.files)                # ['episode001', 'episode002']\n",
    "print(data[\"episode000\"].shape)  # (5, 11)\n",
    "print(data[\"episode000\"][0])\n",
    "print(data[\"episode000\"][2])\n",
    "#print(data[\"episode002\"].shape)  # (5, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52e548ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NpzFile '/AILAB-summer-school-2025/dataset_all.npz' with keys: episode000, episode001, episode002, episode003, episode004..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.load(\"/AILAB-summer-school-2025/dataset_all.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "272c1d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['episode000', 'episode001', 'episode002', 'episode003', 'episode004', 'episode005', 'episode006', 'episode007', 'episode008', 'episode009', 'episode010', 'episode011', 'episode012', 'episode013', 'episode014', 'episode015', 'episode016', 'episode017', 'episode018', 'episode019', 'episode020', 'episode021', 'episode022', 'episode023', 'episode024', 'episode025', 'episode026', 'episode027', 'episode028', 'episode029', 'episode030', 'episode031', 'episode032', 'episode033', 'episode034', 'episode035', 'episode036', 'episode037', 'episode038', 'episode039', 'episode040', 'episode041', 'episode042', 'episode043', 'episode044', 'episode045', 'episode046', 'episode047', 'episode048', 'episode049', 'episode050', 'episode051', 'episode052', 'episode053', 'episode054', 'episode055', 'episode056', 'episode057', 'episode058', 'episode059', 'episode060', 'episode061', 'episode062', 'episode063', 'episode064', 'episode065', 'episode066', 'episode067', 'episode068', 'episode069', 'episode070', 'episode071', 'episode072', 'episode073', 'episode074', 'episode075', 'episode076', 'episode077', 'episode078', 'episode079', 'episode080', 'episode081', 'episode082', 'episode083', 'episode084', 'episode085', 'episode086', 'episode087', 'episode088', 'episode089', 'episode090', 'episode091', 'episode092', 'episode093', 'episode094', 'episode095', 'episode096', 'episode097', 'episode098', 'episode099', 'episode100', 'episode101', 'episode102', 'episode103', 'episode104', 'episode105', 'episode106', 'episode107', 'episode108']\n"
     ]
    }
   ],
   "source": [
    "with np.load(\"/AILAB-summer-school-2025/dataset_all.npz\") as f:\n",
    "    print(f.files)  # 어떤 episode까지 있는지\n",
    "    arr = f[\"episode019\"]  # 에러 전까진 열림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bf0301c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load(\"/AILAB-summer-school-2025/dataset_all.npz\") as f:\n",
    "    for k in f.files:\n",
    "        try:\n",
    "            _ = f[k]   # 실제로 로드 시도\n",
    "        except Exception as e:\n",
    "            print(\"에러:\", k, e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94493c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: KeysView(NpzFile '/AILAB-summer-school-2025/simulation_traj_2_20250829_121225_len498_success/robot_state.npz' with keys: EE_pose, obs, applied_torque)\n",
      "EE_pose (346, 7) float32\n",
      "obs (346, 29) float32\n",
      "applied_torque (0,) float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 파일 로드\n",
    "data = np.load(\"/AILAB-summer-school-2025/simulation_traj_2_20250829_121225_len498_success/robot_state.npz\")\n",
    "\n",
    "# 키 목록 출력\n",
    "print(\"Keys:\", data.keys())\n",
    "\n",
    "# 각 key별 value의 shape와 dtype 확인\n",
    "for k in data.keys():\n",
    "    print(k, data[k].shape, data[k].dtype)\n",
    "# for i in range(10):\n",
    "#     print(data['episode000'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adf54987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: KeysView(NpzFile 'dataset_all_afterpregrasp_t3.npz' with keys: episode000, episode001, episode002, episode003, episode004...)\n",
      "[ 3.0280006e-01 -5.6915607e-02  6.2759602e-01  2.3422081e-07\n",
      "  1.0000000e+00 -2.2864535e-06  3.6135559e-06 -1.0000000e+00\n",
      "  4.1523328e-01  1.6660001e-02  5.0053000e-01]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "305"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 파일 로드\n",
    "data = np.load(\"dataset_all_afterpregrasp_t3.npz\")\n",
    "\n",
    "# 키 목록 출력\n",
    "print(\"Keys:\", data.keys())\n",
    "\n",
    "# 각 key별 value의 shape와 dtype 확인\n",
    "# for k in data.keys():\n",
    "#     print(k, data[k].shape, data[k].dtype)\n",
    "for i in range(1):\n",
    "    print(data['episode000'][i])\n",
    "\n",
    "len(data['episode003'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67e01358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 스텝: 58376\n",
      "col00: min=0.154143  max=0.493000  mean=0.334388  std=0.092651\n",
      "col01: min=-0.210957  max=0.616374  mean=0.100874  std=0.299396\n",
      "col02: min=0.016626  max=0.627596  mean=0.283371  std=0.200197\n",
      "col03: min=-0.309463  max=0.296086  mean=-0.014204  std=0.061968\n",
      "col04: min=-0.996798  max=1.000000  mean=0.927372  std=0.326956\n",
      "col05: min=-0.915723  max=0.493847  mean=0.066481  std=0.125248\n",
      "col06: min=-0.280613  max=0.425593  mean=0.041707  std=0.085204\n",
      "col07: min=-1.000000  max=1.000000  mean=-0.259216  std=0.965635\n",
      "col08: min=0.116535  max=0.493333  mean=0.364519  std=0.091515\n",
      "col09: min=-0.096853  max=0.697277  mean=0.187702  std=0.286137\n",
      "col10: min=0.500529  max=1.041341  mean=0.661926  std=0.188267\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "path = \"dataset_all_afterpregrasp_t3.npz\"\n",
    "npz = np.load(path, allow_pickle=True)\n",
    "\n",
    "keys = sorted([k for k in npz.files if k.startswith(\"episode\")])\n",
    "if not keys:\n",
    "    raise ValueError(\"episode### 키가 없습니다.\")\n",
    "\n",
    "rows = []\n",
    "for k in keys:\n",
    "    a = np.asarray(npz[k])\n",
    "    if a.ndim == 1 and a.shape[0] == 11:\n",
    "        a = a[None, :]\n",
    "    if a.ndim != 2:\n",
    "        raise ValueError(f\"{k} shape 이상: {a.shape}\")\n",
    "    if a.shape[1] != 11:\n",
    "        if a.T.shape[1] == 11:\n",
    "            a = a.T\n",
    "        else:\n",
    "            raise ValueError(f\"{k} 열이 11이 아님: {a.shape}\")\n",
    "    rows.append(a)\n",
    "\n",
    "data = np.vstack(rows)          # (total_steps, 11)\n",
    "\n",
    "mins  = np.min(data, axis=0)\n",
    "maxs  = np.max(data, axis=0)\n",
    "means = np.mean(data, axis=0)\n",
    "std = np.std(data, axis = 0)\n",
    "print(f\"총 스텝: {data.shape[0]}\")\n",
    "for i in range(11):\n",
    "    print(f\"col{i:02d}: min={mins[i]:.6f}  max={maxs[i]:.6f}  mean={means[i]:.6f}  std={std[i]:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3271b3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 001  val_mse 1.317846e-02\n",
      "epoch 002  val_mse 9.391064e-03\n",
      "epoch 003  val_mse 8.913240e-03\n",
      "epoch 004  val_mse 7.919356e-03\n",
      "epoch 005  val_mse 8.014124e-03\n",
      "epoch 006  val_mse 7.391402e-03\n",
      "epoch 007  val_mse 7.514128e-03\n",
      "epoch 008  val_mse 7.453711e-03\n",
      "epoch 009  val_mse 7.438667e-03\n",
      "epoch 010  val_mse 7.281705e-03\n",
      "epoch 011  val_mse 7.476663e-03\n",
      "epoch 012  val_mse 7.157443e-03\n",
      "epoch 013  val_mse 7.689284e-03\n",
      "epoch 014  val_mse 7.476829e-03\n",
      "epoch 015  val_mse 7.330987e-03\n",
      "epoch 016  val_mse 7.008285e-03\n",
      "epoch 017  val_mse 7.046681e-03\n",
      "epoch 018  val_mse 6.895128e-03\n",
      "epoch 019  val_mse 6.979250e-03\n",
      "epoch 020  val_mse 6.951074e-03\n",
      "epoch 021  val_mse 7.034390e-03\n",
      "epoch 022  val_mse 7.122997e-03\n",
      "epoch 023  val_mse 6.895843e-03\n",
      "epoch 024  val_mse 7.037154e-03\n",
      "epoch 025  val_mse 7.011926e-03\n",
      "epoch 026  val_mse 6.847736e-03\n",
      "epoch 027  val_mse 7.056269e-03\n",
      "epoch 028  val_mse 6.736265e-03\n",
      "epoch 029  val_mse 6.763923e-03\n",
      "epoch 030  val_mse 6.921984e-03\n",
      "epoch 031  val_mse 6.737926e-03\n",
      "epoch 032  val_mse 6.644336e-03\n",
      "epoch 033  val_mse 7.333722e-03\n",
      "epoch 034  val_mse 6.676173e-03\n",
      "epoch 035  val_mse 6.689753e-03\n",
      "epoch 036  val_mse 7.452159e-03\n",
      "epoch 037  val_mse 6.451261e-03\n",
      "epoch 038  val_mse 7.042587e-03\n",
      "epoch 039  val_mse 6.550990e-03\n",
      "epoch 040  val_mse 6.331922e-03\n",
      "epoch 041  val_mse 6.605886e-03\n",
      "epoch 042  val_mse 6.656420e-03\n",
      "epoch 043  val_mse 6.953543e-03\n",
      "epoch 044  val_mse 6.408886e-03\n",
      "epoch 045  val_mse 6.133090e-03\n",
      "epoch 046  val_mse 6.616864e-03\n",
      "epoch 047  val_mse 6.339637e-03\n",
      "epoch 048  val_mse 6.469597e-03\n",
      "epoch 049  val_mse 6.281842e-03\n",
      "epoch 050  val_mse 6.263616e-03\n",
      "학습 완료. best val MSE: 0.006133090008317606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4019/1351543341.py:257: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(\"il_gru_best3.pt\", map_location=DEVICE)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "# Imitation Learning: s_{t-3:t-1} -> a_t(= s_t[:8])\n",
    "# - 입력: (3, 11), 출력: (8,)\n",
    "# - 초기 t<3 규칙: t=0,1,2 모두 복제 규칙 적용\n",
    "# - 정규화: train split 통계로 표준화(입력 11, 출력 8 각각 별도)\n",
    "\n",
    "import os, json, random, math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# -------------------------\n",
    "# 설정\n",
    "# -------------------------\n",
    "PATH = \"dataset_all_afterpregrasp_t3.npz\"\n",
    "VAL_RATIO = 0.1\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 50\n",
    "LR = 1e-3\n",
    "HIDDEN = 128\n",
    "SEED = 42\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# -------------------------\n",
    "# 유틸\n",
    "# -------------------------\n",
    "def ensure_Tx11(arr):\n",
    "    a = np.asarray(arr)\n",
    "    if a.ndim == 1 and a.shape[0] == 11:\n",
    "        return a[None, :]\n",
    "    if a.ndim == 2 and a.shape[1] == 11:\n",
    "        return a\n",
    "    if a.ndim == 2 and a.shape[0] == 11:\n",
    "        return a.T\n",
    "    raise ValueError(f\"shape must be (T,11) or (11,T), got {a.shape}\")\n",
    "\n",
    "def make_window(ep, t):\n",
    "    \"\"\"규칙대로 (3,11) 윈도우 생성. ep: (T,11)\"\"\"\n",
    "    if t == 0:\n",
    "        w = np.stack([ep[0], ep[0], ep[0]], axis=0)\n",
    "    elif t == 1:\n",
    "        w = np.stack([ep[0], ep[0], ep[0]], axis=0)  # 지시사항: 2번째 스텝 예측도 1번째 3번 복제\n",
    "    elif t == 2:\n",
    "        w = np.stack([ep[0], ep[1], ep[1]], axis=0)  # 지시사항: 1번째 1회 + 2번째 2회\n",
    "    else:\n",
    "        w = ep[t-3:t, :]\n",
    "    return w  # (3,11)\n",
    "\n",
    "class ColumnStandardizer:\n",
    "    def __init__(self, dim):\n",
    "        self.mu = np.zeros(dim, dtype=np.float64)\n",
    "        self.std = np.ones(dim, dtype=np.float64)\n",
    "\n",
    "    def fit(self, X):\n",
    "        # X: (N, dim) or (..., dim)\n",
    "        X2 = X.reshape(-1, X.shape[-1]).astype(np.float64)\n",
    "        self.mu = X2.mean(axis=0)\n",
    "        self.std = X2.std(axis=0)\n",
    "        self.std[self.std < 1e-8] = 1.0  # 분산 0 보호\n",
    "\n",
    "    def transform(self, X):\n",
    "        return (X - self.mu) / self.std\n",
    "\n",
    "    def inverse(self, Xn):\n",
    "        return Xn * self.std + self.mu\n",
    "\n",
    "    def state(self):\n",
    "        return {\"mu\": self.mu.tolist(), \"std\": self.std.tolist()}\n",
    "\n",
    "class ILDataset(Dataset):\n",
    "    def __init__(self, npz, keys, x_norm=None, y_norm=None):\n",
    "        self.samples = []  # list of (X[3,11], y[8])\n",
    "        for k in keys:\n",
    "            ep = ensure_Tx11(npz[k])\n",
    "            T = ep.shape[0]\n",
    "            for t in range(T):\n",
    "                # 타깃은 s_t[:8]\n",
    "                y = ep[t, :8]\n",
    "                X = make_window(ep, t)  # (3,11)\n",
    "                self.samples.append((X, y))\n",
    "        self.x_norm = x_norm\n",
    "        self.y_norm = y_norm\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X, y = self.samples[idx]\n",
    "        if self.x_norm is not None:\n",
    "            X = self.x_norm.transform(X)  # (3,11) 표준화\n",
    "        if self.y_norm is not None:\n",
    "            y = self.y_norm.transform(y)  # (8,)   표준화\n",
    "        X = torch.from_numpy(X.astype(np.float32))           # (3,11)\n",
    "        y = torch.from_numpy(y.astype(np.float32))           # (8,)\n",
    "        return X, y\n",
    "\n",
    "class GRUPolicy(nn.Module):\n",
    "    # 입력: (B,3,11) -> GRU -> head -> (B,8)\n",
    "    def __init__(self, in_dim=11, hidden=128, out_dim=8, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_size=in_dim, hidden_size=hidden, num_layers=num_layers, batch_first=True)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden, out_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # x: (B,3,11)\n",
    "        h, _ = self.gru(x)\n",
    "        last = h[:, -1, :]\n",
    "        return self.head(last)  # (B,8)\n",
    "\n",
    "class MLPPolicy(nn.Module):\n",
    "    # 입력: (B,3,11) -> flatten -> MLP -> (B,8)\n",
    "    def __init__(self, in_dim=11, win=3, hidden=256, out_dim=8):\n",
    "        super().__init__()\n",
    "        self.win = win\n",
    "        self.in_dim = in_dim\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim*win, hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden, out_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # x: (B,3,11)\n",
    "        B = x.size(0)\n",
    "        x = x.view(B, self.win * self.in_dim)  # (B,33)\n",
    "        return self.net(x)  # (B,8)\n",
    "\n",
    "# -------------------------\n",
    "# 데이터 로드 및 split\n",
    "# -------------------------\n",
    "npz = np.load(PATH, allow_pickle=True)\n",
    "keys = sorted([k for k in npz.files if k.startswith(\"episode\")])\n",
    "if not keys:\n",
    "    raise RuntimeError(\"episode### 키가 없음\")\n",
    "\n",
    "# 에피소드 단위 분할\n",
    "n_val = max(1, int(len(keys) * VAL_RATIO))\n",
    "random.shuffle(keys)\n",
    "val_keys = sorted(keys[:n_val])\n",
    "train_keys = sorted(keys[n_val:])\n",
    "\n",
    "# 정규화 통계 추출을 위해 train 전부 펼치기\n",
    "train_states = []\n",
    "train_targets = []\n",
    "for k in train_keys:\n",
    "    ep = ensure_Tx11(npz[k])\n",
    "    T = ep.shape[0]\n",
    "    # 입력용: 윈도우 3개 모두 포함하므로, 먼저 원본 분포 기준으로 통계 계산\n",
    "    # 입력 정규화는 state 컬럼별 통계 필요 → 원본 ep 전 구간 사용\n",
    "    train_states.append(ep)           # (T,11)\n",
    "    train_targets.append(ep[:, :8])   # (T,8)\n",
    "\n",
    "train_states = np.concatenate(train_states, axis=0)  # (S,11)\n",
    "train_targets = np.concatenate(train_targets, axis=0)  # (S,8)\n",
    "\n",
    "x_norm = ColumnStandardizer(dim=11)\n",
    "y_norm = ColumnStandardizer(dim=8)\n",
    "x_norm.fit(train_states)\n",
    "y_norm.fit(train_targets)\n",
    "\n",
    "# 데이터셋 생성\n",
    "train_ds = ILDataset(npz, train_keys, x_norm, y_norm)\n",
    "val_ds   = ILDataset(npz, val_keys,   x_norm, y_norm)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "\n",
    "# -------------------------\n",
    "# 학습 루프\n",
    "# -------------------------\n",
    "model = GRUPolicy(in_dim=11, hidden=HIDDEN, out_dim=8).to(DEVICE)\n",
    "# model = MLPPolicy(in_dim=11, win=3, hidden=256, out_dim=8).to(DEVICE)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    tot, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in val_loader:\n",
    "            X = X.to(DEVICE)   # (B,3,11)\n",
    "            y = y.to(DEVICE)   # (B,8)\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "            bs = X.size(0)\n",
    "            tot += loss.item() * bs\n",
    "            n += bs\n",
    "    return tot / max(n, 1)\n",
    "\n",
    "best_val = math.inf\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    for X, y in train_loader:\n",
    "        X = X.to(DEVICE)   # (B,3,11)\n",
    "        y = y.to(DEVICE)   # (B,8)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    val_mse = evaluate()\n",
    "    print(f\"epoch {epoch:03d}  val_mse {val_mse:.6e}\")\n",
    "    if val_mse < best_val:\n",
    "        best_val = val_mse\n",
    "        torch.save({\"model\": model.state_dict(),\n",
    "                    \"x_norm\": x_norm.state(),\n",
    "                    \"y_norm\": y_norm.state()}, \"il_gru_best3.pt\")\n",
    "\n",
    "print(\"학습 완료. best val MSE:\", best_val)\n",
    "\n",
    "# -------------------------\n",
    "# 추론 함수 예시\n",
    "# -------------------------\n",
    "def load_norm(state):\n",
    "    sd_x = np.array(state[\"x_norm\"][\"mu\"], dtype=np.float64)\n",
    "    sd_y = np.array(state[\"y_norm\"][\"mu\"], dtype=np.float64)  # not used here\n",
    "    # 이미 ColumnStandardizer 상태 저장했으므로 그대로 복원\n",
    "    nx = ColumnStandardizer(11)\n",
    "    ny = ColumnStandardizer(8)\n",
    "    nx.mu = np.array(state[\"x_norm\"][\"mu\"], dtype=np.float64)\n",
    "    nx.std = np.array(state[\"x_norm\"][\"std\"], dtype=np.float64)\n",
    "    ny.mu = np.array(state[\"y_norm\"][\"mu\"], dtype=np.float64)\n",
    "    ny.std = np.array(state[\"y_norm\"][\"std\"], dtype=np.float64)\n",
    "    return nx, ny\n",
    "\n",
    "def predict_action(model, x_norm, y_norm, history_ks):\n",
    "    \"\"\"\n",
    "    history_ks: numpy array of shape (k,11), k in {1,2,3}\n",
    "    규칙에 맞춰 (3,11)로 만들고 정규화하여 예측. 반환은 비정규화된 (8,)\n",
    "    \"\"\"\n",
    "    hist = ensure_Tx11(history_ks)  # (k,11)\n",
    "    if hist.shape[0] == 1:\n",
    "        X = np.stack([hist[0], hist[0], hist[0]], axis=0)\n",
    "    elif hist.shape[0] == 2:\n",
    "        X = np.stack([hist[0], hist[1], hist[1]], axis=0)\n",
    "    else:\n",
    "        X = hist[-3:, :]\n",
    "    Xn = x_norm.transform(X).astype(np.float32)\n",
    "    xt = torch.from_numpy(Xn)[None, ...].to(DEVICE)  # (1,3,11)\n",
    "    with torch.no_grad():\n",
    "        yn = model(xt).cpu().numpy()[0]  # (8,)\n",
    "    y = y_norm.inverse(yn)\n",
    "    return y  # (8,)\n",
    "\n",
    "# 저장된 베스트 체크포인트 복원 예시\n",
    "ckpt = torch.load(\"il_gru_best3.pt\", map_location=DEVICE)\n",
    "\n",
    "# model = MLPPolicy(in_dim=11, win=3, hidden=256, out_dim=8).to(DEVICE)\n",
    "# model.load_state_dict(ckpt[\"model\"])\n",
    "model = GRUPolicy(in_dim=11, hidden=HIDDEN, out_dim=8).to(DEVICE)  # GRU로 생성\n",
    "model.load_state_dict(ckpt[\"model\"], strict=True)\n",
    "x_norm_re, y_norm_re = load_norm({\n",
    "    \"x_norm\": ckpt[\"x_norm\"],\n",
    "    \"y_norm\": ckpt[\"y_norm\"],\n",
    "})\n",
    "\n",
    "# 예시 입력으로 동작 확인\n",
    "# hist = np.array([\n",
    "#   [0.2955, -0.0532, 0.1080, -0.0028, 1.0029, -0.0139, -0.0057, -1.0000, 0.1029, -0.2139, -0.0357],\n",
    "#   [0.2890, -0.1274, 0.0823,  0.0184, 0.9880, -0.0451,  0.0118, -1.0000, 0.0229, -0.7131, -0.3056],\n",
    "#   [0.2899, -0.1282, 0.0969,  0.0253, 0.9847, -0.0472,  0.0422,  1.0000, -0.0249, -1.0109, -0.0057],\n",
    "# ], dtype=np.float32)\n",
    "# act8 = predict_action(model, x_norm_re, y_norm_re, hist)\n",
    "# print(\"pred action(8):\", act8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c24f3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred action(8): [ 0.30003545 -0.09169847  0.25209087  0.01513988  1.00816255  0.05462717\n",
      "  0.07752625  1.12046635]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 예시 입력으로 동작 확인\n",
    "hist = np.array([\n",
    "  [ 0.3047, -0.0590, 0.2224 ,  0.0041,  0.9997,  0.0149,  0.0179,  1.0000, 0.3047, -0.0590, 0.02198],\n",
    "  [0.3028, -0.0620,  0.2207,  0.0081,  0.9987,  0.0268,  0.0416,  1.0000, 0.3047, -0.0590, 0.0198],\n",
    "  [0.3001, -0.0655,  0.2198,  0.0122,  0.9970,  0.0366,  0.0671,  1.0000, 0.3047, -0.0590, 0.0198],\n",
    "], dtype=np.float32)\n",
    "act8 = predict_action(model, x_norm_re, y_norm_re, hist)\n",
    "print(\"pred action(8):\", act8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e7c380",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
