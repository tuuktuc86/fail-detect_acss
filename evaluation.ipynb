{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2369062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['episode000', 'episode001', 'episode002', 'episode003', 'episode004', 'episode005', 'episode006', 'episode007', 'episode008', 'episode009', 'episode010', 'episode011', 'episode012', 'episode013', 'episode014', 'episode015', 'episode016', 'episode017', 'episode018', 'episode019', 'episode020', 'episode021', 'episode022', 'episode023', 'episode024', 'episode025', 'episode026', 'episode027', 'episode028', 'episode029', 'episode030', 'episode031', 'episode032', 'episode033', 'episode034', 'episode035', 'episode036', 'episode037', 'episode038', 'episode039', 'episode040', 'episode041', 'episode042', 'episode043', 'episode044', 'episode045', 'episode046', 'episode047', 'episode048', 'episode049', 'episode050', 'episode051', 'episode052', 'episode053', 'episode054', 'episode055', 'episode056', 'episode057', 'episode058', 'episode059', 'episode060', 'episode061', 'episode062', 'episode063', 'episode064', 'episode065', 'episode066', 'episode067', 'episode068', 'episode069', 'episode070', 'episode071', 'episode072', 'episode073', 'episode074', 'episode075', 'episode076', 'episode077', 'episode078', 'episode079', 'episode080', 'episode081', 'episode082', 'episode083', 'episode084', 'episode085', 'episode086', 'episode087', 'episode088', 'episode089', 'episode090', 'episode091', 'episode092', 'episode093', 'episode094', 'episode095', 'episode096', 'episode097', 'episode098', 'episode099', 'episode100', 'episode101', 'episode102', 'episode103', 'episode104', 'episode105', 'episode106', 'episode107', 'episode108']\n",
      "(318, 11)\n",
      "[ 3.0280012e-01 -5.6915589e-02  1.1275961e+00  6.6436871e-07\n",
      "  9.9999994e-01 -3.4745012e-06  3.8833377e-06  1.0000000e+00\n",
      "  4.2091480e-01  2.2506712e-02  5.0053000e-01]\n",
      "[ 3.0280003e-01 -5.6915559e-02  1.1275964e+00  7.0907276e-07\n",
      "  9.9999988e-01 -3.2411465e-06  3.8638618e-06  1.0000000e+00\n",
      "  4.2091480e-01  2.2506712e-02  5.0053000e-01]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.load(\"/AILAB-summer-school-2025/dataset_all.npz\")\n",
    "print(data.files)                # ['episode001', 'episode002']\n",
    "print(data[\"episode000\"].shape)  # (5, 11)\n",
    "print(data[\"episode000\"][0])\n",
    "print(data[\"episode000\"][2])\n",
    "#print(data[\"episode002\"].shape)  # (5, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52e548ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NpzFile '/AILAB-summer-school-2025/dataset_all.npz' with keys: episode000, episode001, episode002, episode003, episode004..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.load(\"/AILAB-summer-school-2025/dataset_all.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "272c1d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['episode000', 'episode001', 'episode002', 'episode003', 'episode004', 'episode005', 'episode006', 'episode007', 'episode008', 'episode009', 'episode010', 'episode011', 'episode012', 'episode013', 'episode014', 'episode015', 'episode016', 'episode017', 'episode018', 'episode019', 'episode020', 'episode021', 'episode022', 'episode023', 'episode024', 'episode025', 'episode026', 'episode027', 'episode028', 'episode029', 'episode030', 'episode031', 'episode032', 'episode033', 'episode034', 'episode035', 'episode036', 'episode037', 'episode038', 'episode039', 'episode040', 'episode041', 'episode042', 'episode043', 'episode044', 'episode045', 'episode046', 'episode047', 'episode048', 'episode049', 'episode050', 'episode051', 'episode052', 'episode053', 'episode054', 'episode055', 'episode056', 'episode057', 'episode058', 'episode059', 'episode060', 'episode061', 'episode062', 'episode063', 'episode064', 'episode065', 'episode066', 'episode067', 'episode068', 'episode069', 'episode070', 'episode071', 'episode072', 'episode073', 'episode074', 'episode075', 'episode076', 'episode077', 'episode078', 'episode079', 'episode080', 'episode081', 'episode082', 'episode083', 'episode084', 'episode085', 'episode086', 'episode087', 'episode088', 'episode089', 'episode090', 'episode091', 'episode092', 'episode093', 'episode094', 'episode095', 'episode096', 'episode097', 'episode098', 'episode099', 'episode100', 'episode101', 'episode102', 'episode103', 'episode104', 'episode105', 'episode106', 'episode107', 'episode108']\n"
     ]
    }
   ],
   "source": [
    "with np.load(\"/AILAB-summer-school-2025/dataset_all.npz\") as f:\n",
    "    print(f.files)  # 어떤 episode까지 있는지\n",
    "    arr = f[\"episode019\"]  # 에러 전까진 열림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bf0301c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load(\"/AILAB-summer-school-2025/dataset_all.npz\") as f:\n",
    "    for k in f.files:\n",
    "        try:\n",
    "            _ = f[k]   # 실제로 로드 시도\n",
    "        except Exception as e:\n",
    "            print(\"에러:\", k, e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "94493c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: KeysView(NpzFile 'success_data_raw/success_episode1462_steps455/robot_state.npz' with keys: EE_pose, obs, applied_torque)\n",
      "EE_pose (278, 7) float32\n",
      "obs (278, 29) float32\n",
      "applied_torque (278, 9) float32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 파일 로드\n",
    "data = np.load(\"success_data_raw/success_episode1462_steps455/robot_state.npz\")\n",
    "\n",
    "# 키 목록 출력\n",
    "print(\"Keys:\", data.keys())\n",
    "\n",
    "# 각 key별 value의 shape와 dtype 확인\n",
    "for k in data.keys():\n",
    "    print(k, data[k].shape, data[k].dtype)\n",
    "# for i in range(10):\n",
    "#     print(data['episode000'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "adf54987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: KeysView(NpzFile 'all_success_episodes_trimmed.npz' with keys: episode1000, episode1001, episode1002, episode1003, episode1004...)\n",
      "[ 3.0476150e-01 -5.8437835e-02  6.2238431e-01  9.1318041e-05\n",
      "  9.9975663e-01  1.2026275e-02  1.8492438e-02  1.0000000e+00\n",
      "  4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      "[ 3.0275521e-01 -6.1926670e-02  6.2058020e-01  2.7275644e-04\n",
      "  9.9886614e-01  2.0756803e-02  4.2840101e-02  1.0000000e+00\n",
      "  4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      "[ 2.9985350e-01 -6.6377878e-02  6.1967075e-01  9.5906667e-04\n",
      "  9.9723947e-01  2.7530653e-02  6.8952799e-02  1.0000000e+00\n",
      "  4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      "[ 2.9682568e-01 -7.1321137e-02  6.1865270e-01  2.2023534e-03\n",
      "  9.9493206e-01  3.3045553e-02  9.4939210e-02  1.0000000e+00\n",
      "  4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      "[ 2.9370421e-01 -7.6540701e-02  6.1751521e-01  4.0520951e-03\n",
      "  9.9196106e-01  3.7585415e-02  1.2076450e-01  1.0000000e+00\n",
      "  4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      "[ 2.9048979e-01 -8.1954360e-02  6.1624789e-01  6.5015182e-03\n",
      "  9.8835087e-01  4.1267153e-02  1.4634599e-01  1.0000000e+00\n",
      "  4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      "[ 2.8723085e-01 -8.7535053e-02  6.1478794e-01  9.5053352e-03\n",
      "  9.8415577e-01  4.4139467e-02  1.7146057e-01  1.0000000e+00\n",
      "  4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      "[ 2.8410837e-01 -9.3283616e-02  6.1298525e-01  1.3031285e-02\n",
      "  9.7943616e-01  4.6231072e-02  1.9595329e-01  1.0000000e+00\n",
      "  4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      "[ 2.8120217e-01 -9.9174075e-02  6.1076128e-01  1.7052561e-02\n",
      "  9.7424710e-01  4.7597960e-02  2.1974127e-01  1.0000000e+00\n",
      "  4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      "[ 2.7855840e-01 -1.0515042e-01  6.0807085e-01  2.1554383e-02\n",
      "  9.6863776e-01  4.8320904e-02  2.4277817e-01  1.0000000e+00\n",
      "  4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      "[ 2.7614048e-01 -1.1115326e-01  6.0488069e-01  2.6499990e-02\n",
      "  9.6268272e-01  4.8481185e-02  2.6493239e-01  1.0000000e+00\n",
      "  4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      "[ 2.7334604e-01 -1.1695453e-01  6.0048628e-01  3.1358294e-02\n",
      "  9.5702660e-01  4.8286337e-02  2.8422731e-01  1.0000000e+00\n",
      "  4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      "[ 2.6996845e-01 -1.2235403e-01  5.9422004e-01  3.5605889e-02\n",
      "  9.5226133e-01  4.7911759e-02  2.9939115e-01  1.0000000e+00\n",
      "  4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      "[ 2.6638100e-01 -1.2734093e-01  5.8610952e-01  3.9233319e-02\n",
      "  9.4847286e-01  4.7431868e-02  3.1082195e-01  1.0000000e+00\n",
      "  4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      "[ 2.6291415e-01 -1.3189055e-01  5.7618463e-01  4.2229228e-02\n",
      "  9.4570541e-01  4.6932150e-02  3.1883436e-01  1.0000000e+00\n",
      "  4.0991434e-01  4.4602789e-03  5.3000380e-04]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'episode003 is not a file in the archive'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m15\u001b[39m):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepisode0001\u001b[39m\u001b[38;5;124m'\u001b[39m][i])\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepisode003\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py:263\u001b[0m, in \u001b[0;36mNpzFile.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mread(key)\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 263\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a file in the archive\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'episode003 is not a file in the archive'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 파일 로드\n",
    "#data = np.load(\"dataset_all_afterpregrasp_t3.npz\")\n",
    "data = np.load(\"all_success_episodes_trimmed.npz\")\n",
    "\n",
    "# 키 목록 출력\n",
    "print(\"Keys:\", data.keys())\n",
    "\n",
    "# 각 key별 value의 shape와 dtype 확인\n",
    "# for k in data.keys():\n",
    "#     print(k, data[k].shape, data[k].dtype)\n",
    "for i in range(15):\n",
    "    print(data['episode0001'][i])\n",
    "\n",
    "len(data['episode003'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67e01358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 스텝: 58376\n",
      "col00: min=0.154143  max=0.493000  mean=0.334388  std=0.092651\n",
      "col01: min=-0.210957  max=0.616374  mean=0.100874  std=0.299396\n",
      "col02: min=0.016626  max=0.627596  mean=0.283371  std=0.200197\n",
      "col03: min=-0.309463  max=0.296086  mean=-0.014204  std=0.061968\n",
      "col04: min=-0.996798  max=1.000000  mean=0.927372  std=0.326956\n",
      "col05: min=-0.915723  max=0.493847  mean=0.066481  std=0.125248\n",
      "col06: min=-0.280613  max=0.425593  mean=0.041707  std=0.085204\n",
      "col07: min=-1.000000  max=1.000000  mean=-0.259216  std=0.965635\n",
      "col08: min=0.116535  max=0.493333  mean=0.364519  std=0.091515\n",
      "col09: min=-0.096853  max=0.697277  mean=0.187702  std=0.286137\n",
      "col10: min=0.500529  max=1.041341  mean=0.661926  std=0.188267\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "path = \"dataset_all_afterpregrasp_t3.npz\"\n",
    "npz = np.load(path, allow_pickle=True)\n",
    "\n",
    "keys = sorted([k for k in npz.files if k.startswith(\"episode\")])\n",
    "if not keys:\n",
    "    raise ValueError(\"episode### 키가 없습니다.\")\n",
    "\n",
    "rows = []\n",
    "for k in keys:\n",
    "    a = np.asarray(npz[k])\n",
    "    if a.ndim == 1 and a.shape[0] == 11:\n",
    "        a = a[None, :]\n",
    "    if a.ndim != 2:\n",
    "        raise ValueError(f\"{k} shape 이상: {a.shape}\")\n",
    "    if a.shape[1] != 11:\n",
    "        if a.T.shape[1] == 11:\n",
    "            a = a.T\n",
    "        else:\n",
    "            raise ValueError(f\"{k} 열이 11이 아님: {a.shape}\")\n",
    "    rows.append(a)\n",
    "\n",
    "data = np.vstack(rows)          # (total_steps, 11)\n",
    "\n",
    "mins  = np.min(data, axis=0)\n",
    "maxs  = np.max(data, axis=0)\n",
    "means = np.mean(data, axis=0)\n",
    "std = np.std(data, axis = 0)\n",
    "print(f\"총 스텝: {data.shape[0]}\")\n",
    "for i in range(11):\n",
    "    print(f\"col{i:02d}: min={mins[i]:.6f}  max={maxs[i]:.6f}  mean={means[i]:.6f}  std={std[i]:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a1614765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 스텝: 440971\n",
      "col00: min=-0.047638  max=0.514692  mean=0.325167  std=0.087593\n",
      "col01: min=-0.274683  max=0.616609  mean=0.112347  std=0.291268\n",
      "col02: min=-0.477423  max=0.628743  mean=0.266479  std=0.219362\n",
      "col03: min=-0.309463  max=0.335084  mean=-0.006398  std=0.067798\n",
      "col04: min=-0.997373  max=1.000000  mean=0.904946  std=0.386795\n",
      "col05: min=-0.928518  max=0.612728  mean=0.060631  std=0.117553\n",
      "col06: min=-0.350285  max=0.470894  mean=0.043981  std=0.094149\n",
      "col07: min=-1.000000  max=1.000000  mean=-0.239360  std=0.972058\n",
      "col08: min=0.116535  max=0.549802  mean=0.356000  std=0.085272\n",
      "col09: min=-0.152300  max=0.700684  mean=0.197933  std=0.277439\n",
      "col10: min=0.000492  max=0.545463  mean=0.160865  std=0.189312\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "path = \"all_success_episodes_trimmed.npz\"\n",
    "npz = np.load(path, allow_pickle=True)\n",
    "\n",
    "keys = sorted([k for k in npz.files if k.startswith(\"episode\")])\n",
    "if not keys:\n",
    "    raise ValueError(\"episode### 키가 없습니다.\")\n",
    "\n",
    "rows = []\n",
    "for k in keys:\n",
    "    a = np.asarray(npz[k])\n",
    "    if a.ndim == 1 and a.shape[0] == 11:\n",
    "        a = a[None, :]\n",
    "    if a.ndim != 2:\n",
    "        raise ValueError(f\"{k} shape 이상: {a.shape}\")\n",
    "    if a.shape[1] != 11:\n",
    "        if a.T.shape[1] == 11:\n",
    "            a = a.T\n",
    "        else:\n",
    "            raise ValueError(f\"{k} 열이 11이 아님: {a.shape}\")\n",
    "    rows.append(a)\n",
    "\n",
    "data = np.vstack(rows)          # (total_steps, 11)\n",
    "\n",
    "mins  = np.min(data, axis=0)\n",
    "maxs  = np.max(data, axis=0)\n",
    "means = np.mean(data, axis=0)\n",
    "std = np.std(data, axis = 0)\n",
    "print(f\"총 스텝: {data.shape[0]}\")\n",
    "for i in range(11):\n",
    "    print(f\"col{i:02d}: min={mins[i]:.6f}  max={maxs[i]:.6f}  mean={means[i]:.6f}  std={std[i]:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3271b3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 001  val_mse 1.287224e-02\n",
      "epoch 002  val_mse 1.217177e-02\n",
      "epoch 003  val_mse 1.244959e-02\n",
      "epoch 004  val_mse 1.220696e-02\n",
      "epoch 005  val_mse 1.174093e-02\n",
      "epoch 006  val_mse 1.170401e-02\n",
      "epoch 007  val_mse 1.119618e-02\n",
      "epoch 008  val_mse 1.393031e-02\n",
      "epoch 009  val_mse 1.142516e-02\n",
      "epoch 010  val_mse 1.108298e-02\n",
      "epoch 011  val_mse 1.195978e-02\n",
      "epoch 012  val_mse 1.080690e-02\n",
      "epoch 013  val_mse 1.066142e-02\n",
      "epoch 014  val_mse 1.080508e-02\n",
      "epoch 015  val_mse 1.125023e-02\n",
      "epoch 016  val_mse 1.091209e-02\n",
      "epoch 017  val_mse 1.107506e-02\n",
      "epoch 018  val_mse 1.113371e-02\n",
      "epoch 019  val_mse 1.101433e-02\n",
      "epoch 020  val_mse 1.329919e-02\n",
      "epoch 021  val_mse 1.041583e-02\n",
      "epoch 022  val_mse 1.055665e-02\n",
      "epoch 023  val_mse 1.118505e-02\n",
      "epoch 024  val_mse 1.098781e-02\n",
      "epoch 025  val_mse 1.106497e-02\n",
      "epoch 026  val_mse 9.946454e-03\n",
      "epoch 027  val_mse 1.034746e-02\n",
      "epoch 028  val_mse 1.078712e-02\n",
      "epoch 029  val_mse 1.088495e-02\n",
      "epoch 030  val_mse 1.076658e-02\n",
      "epoch 031  val_mse 1.073162e-02\n",
      "epoch 032  val_mse 1.000244e-02\n",
      "epoch 033  val_mse 1.040721e-02\n",
      "epoch 034  val_mse 1.062905e-02\n",
      "epoch 035  val_mse 1.073895e-02\n",
      "epoch 036  val_mse 1.201436e-02\n",
      "epoch 037  val_mse 1.051055e-02\n",
      "epoch 038  val_mse 1.109239e-02\n",
      "epoch 039  val_mse 1.025722e-02\n",
      "epoch 040  val_mse 1.133750e-02\n",
      "epoch 041  val_mse 9.278359e-03\n",
      "epoch 042  val_mse 9.531316e-03\n",
      "epoch 043  val_mse 1.023579e-02\n",
      "epoch 044  val_mse 1.130431e-02\n",
      "epoch 045  val_mse 1.048893e-02\n",
      "epoch 046  val_mse 9.126673e-03\n",
      "epoch 047  val_mse 1.008690e-02\n",
      "epoch 048  val_mse 9.391900e-03\n",
      "epoch 049  val_mse 9.981347e-03\n",
      "epoch 050  val_mse 9.834435e-03\n",
      "학습 완료. best val MSE: 0.009126672963600488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4019/3620179049.py:247: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(\"il_gru_best6.pt\", map_location=DEVICE)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'il_gru_best6.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 247\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# 저장된 베스트 체크포인트 복원 예시\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mil_gru_best6.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# model = MLPPolicy(in_dim=11, win=3, hidden=256, out_dim=8).to(DEVICE)\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# model.load_state_dict(ckpt[\"model\"])\u001b[39;00m\n\u001b[1;32m    251\u001b[0m model \u001b[38;5;241m=\u001b[39m GRUPolicy(in_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m11\u001b[39m, hidden\u001b[38;5;241m=\u001b[39mHIDDEN, out_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\u001b[38;5;241m.\u001b[39mto(DEVICE)  \u001b[38;5;66;03m# GRU로 생성\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py:1319\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1317\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1319\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1321\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py:659\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 659\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    661\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py:640\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 640\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'il_gru_best6.pt'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "# Imitation Learning: s_{t-3:t-1} -> a_t(= s_t[:8])\n",
    "# - 입력: (3, 11), 출력: (8,)\n",
    "# - 초기 t<3 규칙: t=0,1,2 모두 복제 규칙 적용\n",
    "# - 정규화: train split 통계로 표준화(입력 11, 출력 8 각각 별도)\n",
    "\n",
    "import os, json, random, math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# -------------------------\n",
    "# 설정\n",
    "# -------------------------\n",
    "PATH = \"all_success_episodes_trimmed.npz\"\n",
    "VAL_RATIO = 0.1\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 50\n",
    "LR = 1e-3\n",
    "HIDDEN = 128\n",
    "SEED = 42\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# -------------------------\n",
    "# 유틸\n",
    "# -------------------------\n",
    "def ensure_Tx11(arr):\n",
    "    a = np.asarray(arr)\n",
    "    if a.ndim == 1 and a.shape[0] == 11:\n",
    "        return a[None, :]\n",
    "    if a.ndim == 2 and a.shape[1] == 11:\n",
    "        return a\n",
    "    if a.ndim == 2 and a.shape[0] == 11:\n",
    "        return a.T\n",
    "    raise ValueError(f\"shape must be (T,11) or (11,T), got {a.shape}\")\n",
    "\n",
    "def make_window(ep, t):\n",
    "    \"\"\"규칙대로 (3,11) 윈도우 생성. ep: (T,11)\"\"\"\n",
    "    if t == 0:\n",
    "        w = np.stack([ep[0], ep[0], ep[0]], axis=0)\n",
    "    elif t == 1:\n",
    "        w = np.stack([ep[0], ep[0], ep[0]], axis=0)  # 지시사항: 2번째 스텝 예측도 1번째 3번 복제\n",
    "    elif t == 2:\n",
    "        w = np.stack([ep[0], ep[1], ep[1]], axis=0)  # 지시사항: 1번째 1회 + 2번째 2회\n",
    "    else:\n",
    "        w = ep[t-3:t, :]\n",
    "    return w  # (3,11)\n",
    "\n",
    "class ColumnStandardizer:\n",
    "    def __init__(self, dim):\n",
    "        self.mu = np.zeros(dim, dtype=np.float64)\n",
    "        self.std = np.ones(dim, dtype=np.float64)\n",
    "\n",
    "    def fit(self, X):\n",
    "        # X: (N, dim) or (..., dim)\n",
    "        X2 = X.reshape(-1, X.shape[-1]).astype(np.float64)\n",
    "        self.mu = X2.mean(axis=0)\n",
    "        self.std = X2.std(axis=0)\n",
    "        self.std[self.std < 1e-8] = 1.0  # 분산 0 보호\n",
    "\n",
    "    def transform(self, X):\n",
    "        return (X - self.mu) / self.std\n",
    "\n",
    "    def inverse(self, Xn):\n",
    "        return Xn * self.std + self.mu\n",
    "\n",
    "    def state(self):\n",
    "        return {\"mu\": self.mu.tolist(), \"std\": self.std.tolist()}\n",
    "\n",
    "class ILDataset(Dataset):\n",
    "    def __init__(self, npz, keys, x_norm=None, y_norm=None):\n",
    "        self.samples = []  # list of (X[3,11], y[8])\n",
    "        for k in keys:\n",
    "            ep = ensure_Tx11(npz[k])\n",
    "            T = ep.shape[0]\n",
    "            for t in range(T):\n",
    "                # 타깃은 s_t[:8]\n",
    "                y = ep[t, :8]\n",
    "                X = make_window(ep, t)  # (3,11)\n",
    "                self.samples.append((X, y))\n",
    "        self.x_norm = x_norm\n",
    "        self.y_norm = y_norm\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X, y = self.samples[idx]\n",
    "        if self.x_norm is not None:\n",
    "            X = self.x_norm.transform(X)  # (3,11) 표준화\n",
    "        if self.y_norm is not None:\n",
    "            y = self.y_norm.transform(y)  # (8,)   표준화\n",
    "        X = torch.from_numpy(X.astype(np.float32))           # (3,11)\n",
    "        y = torch.from_numpy(y.astype(np.float32))           # (8,)\n",
    "        return X, y\n",
    "\n",
    "class GRUPolicy(nn.Module):\n",
    "    # 입력: (B,3,11) -> GRU -> head -> (B,8)\n",
    "    def __init__(self, in_dim=11, hidden=128, out_dim=8, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_size=in_dim, hidden_size=hidden, num_layers=num_layers, batch_first=True)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden, out_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # x: (B,3,11)\n",
    "        h, _ = self.gru(x)\n",
    "        last = h[:, -1, :]\n",
    "        return self.head(last)  # (B,8)\n",
    "\n",
    "class MLPPolicy(nn.Module):\n",
    "    # 입력: (B,3,11) -> flatten -> MLP -> (B,8)\n",
    "    def __init__(self, in_dim=11, win=3, hidden=256, out_dim=8):\n",
    "        super().__init__()\n",
    "        self.win = win\n",
    "        self.in_dim = in_dim\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim*win, hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden, out_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # x: (B,3,11)\n",
    "        B = x.size(0)\n",
    "        x = x.view(B, self.win * self.in_dim)  # (B,33)\n",
    "        return self.net(x)  # (B,8)\n",
    "\n",
    "# -------------------------\n",
    "# 데이터 로드 및 split\n",
    "# -------------------------\n",
    "npz = np.load(PATH, allow_pickle=True)\n",
    "keys = sorted([k for k in npz.files if k.startswith(\"episode\")])\n",
    "if not keys:\n",
    "    raise RuntimeError(\"episode### 키가 없음\")\n",
    "\n",
    "# 에피소드 단위 분할\n",
    "n_val = max(1, int(len(keys) * VAL_RATIO))\n",
    "random.shuffle(keys)\n",
    "val_keys = sorted(keys[:n_val])\n",
    "train_keys = sorted(keys[n_val:])\n",
    "\n",
    "# 정규화 통계 추출을 위해 train 전부 펼치기\n",
    "train_states = []\n",
    "train_targets = []\n",
    "for k in train_keys:\n",
    "    ep = ensure_Tx11(npz[k])\n",
    "    T = ep.shape[0]\n",
    "    # 입력용: 윈도우 3개 모두 포함하므로, 먼저 원본 분포 기준으로 통계 계산\n",
    "    # 입력 정규화는 state 컬럼별 통계 필요 → 원본 ep 전 구간 사용\n",
    "    train_states.append(ep)           # (T,11)\n",
    "    train_targets.append(ep[:, :8])   # (T,8)\n",
    "\n",
    "train_states = np.concatenate(train_states, axis=0)  # (S,11)\n",
    "train_targets = np.concatenate(train_targets, axis=0)  # (S,8)\n",
    "\n",
    "x_norm = ColumnStandardizer(dim=11)\n",
    "y_norm = ColumnStandardizer(dim=8)\n",
    "x_norm.fit(train_states)\n",
    "y_norm.fit(train_targets)\n",
    "\n",
    "# 데이터셋 생성\n",
    "train_ds = ILDataset(npz, train_keys, x_norm, y_norm)\n",
    "val_ds   = ILDataset(npz, val_keys,   x_norm, y_norm)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "\n",
    "# -------------------------\n",
    "# 학습 루프\n",
    "# -------------------------\n",
    "#model = GRUPolicy(in_dim=11, hidden=HIDDEN, out_dim=8).to(DEVICE)\n",
    "model = MLPPolicy(in_dim=11, win=3, hidden=256, out_dim=8).to(DEVICE)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    tot, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in val_loader:\n",
    "            X = X.to(DEVICE)   # (B,3,11)\n",
    "            y = y.to(DEVICE)   # (B,8)\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "            bs = X.size(0)\n",
    "            tot += loss.item() * bs\n",
    "            n += bs\n",
    "    return tot / max(n, 1)\n",
    "\n",
    "best_val = math.inf\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    for X, y in train_loader:\n",
    "        X = X.to(DEVICE)   # (B,3,11)\n",
    "        y = y.to(DEVICE)   # (B,8)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    val_mse = evaluate()\n",
    "    print(f\"epoch {epoch:03d}  val_mse {val_mse:.6e}\")\n",
    "    if val_mse < best_val:\n",
    "        best_val = val_mse\n",
    "        torch.save({\"model\": model.state_dict(),\n",
    "                    \"x_norm\": x_norm.state(),\n",
    "                    \"y_norm\": y_norm.state()}, \"il_gru_best3.pt\")\n",
    "\n",
    "print(\"학습 완료. best val MSE:\", best_val)\n",
    "\n",
    "# -------------------------\n",
    "# 추론 함수 예시\n",
    "# -------------------------\n",
    "def load_norm(state):\n",
    "    sd_x = np.array(state[\"x_norm\"][\"mu\"], dtype=np.float64)\n",
    "    sd_y = np.array(state[\"y_norm\"][\"mu\"], dtype=np.float64)  # not used here\n",
    "    # 이미 ColumnStandardizer 상태 저장했으므로 그대로 복원\n",
    "    nx = ColumnStandardizer(11)\n",
    "    ny = ColumnStandardizer(8)\n",
    "    nx.mu = np.array(state[\"x_norm\"][\"mu\"], dtype=np.float64)\n",
    "    nx.std = np.array(state[\"x_norm\"][\"std\"], dtype=np.float64)\n",
    "    ny.mu = np.array(state[\"y_norm\"][\"mu\"], dtype=np.float64)\n",
    "    ny.std = np.array(state[\"y_norm\"][\"std\"], dtype=np.float64)\n",
    "    return nx, ny\n",
    "\n",
    "def predict_action(model, x_norm, y_norm, history_ks):\n",
    "    \"\"\"\n",
    "    history_ks: numpy array of shape (k,11), k in {1,2,3}\n",
    "    규칙에 맞춰 (3,11)로 만들고 정규화하여 예측. 반환은 비정규화된 (8,)\n",
    "    \"\"\"\n",
    "    hist = ensure_Tx11(history_ks)  # (k,11)\n",
    "    if hist.shape[0] == 1:\n",
    "        X = np.stack([hist[0], hist[0], hist[0]], axis=0)\n",
    "    elif hist.shape[0] == 2:\n",
    "        X = np.stack([hist[0], hist[1], hist[1]], axis=0)\n",
    "    else:\n",
    "        X = hist[-3:, :]\n",
    "    Xn = x_norm.transform(X).astype(np.float32)\n",
    "    xt = torch.from_numpy(Xn)[None, ...].to(DEVICE)  # (1,3,11)\n",
    "    with torch.no_grad():\n",
    "        yn = model(xt).cpu().numpy()[0]  # (8,)\n",
    "    y = y_norm.inverse(yn)\n",
    "    return y  # (8,)\n",
    "\n",
    "# 저장된 베스트 체크포인트 복원 예시\n",
    "ckpt = torch.load(\"il_gru_best4.pt\", map_location=DEVICE)\n",
    "\n",
    "# model = MLPPolicy(in_dim=11, win=3, hidden=256, out_dim=8).to(DEVICE)\n",
    "# model.load_state_dict(ckpt[\"model\"])\n",
    "model = GRUPolicy(in_dim=11, hidden=HIDDEN, out_dim=8).to(DEVICE)  # GRU로 생성\n",
    "model.load_state_dict(ckpt[\"model\"], strict=True)\n",
    "x_norm_re, y_norm_re = load_norm({\n",
    "    \"x_norm\": ckpt[\"x_norm\"],\n",
    "    \"y_norm\": ckpt[\"y_norm\"],\n",
    "})\n",
    "\n",
    "# 예시 입력으로 동작 확인\n",
    "# hist = np.array([\n",
    "#   [0.2955, -0.0532, 0.1080, -0.0028, 1.0029, -0.0139, -0.0057, -1.0000, 0.1029, -0.2139, -0.0357],\n",
    "#   [0.2890, -0.1274, 0.0823,  0.0184, 0.9880, -0.0451,  0.0118, -1.0000, 0.0229, -0.7131, -0.3056],\n",
    "#   [0.2899, -0.1282, 0.0969,  0.0253, 0.9847, -0.0472,  0.0422,  1.0000, -0.0249, -1.0109, -0.0057],\n",
    "# ], dtype=np.float32)\n",
    "# act8 = predict_action(model, x_norm_re, y_norm_re, hist)\n",
    "# print(\"pred action(8):\", act8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c24f3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred action(8): [ 0.30003545 -0.09169847  0.25209087  0.01513988  1.00816255  0.05462717\n",
      "  0.07752625  1.12046635]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 예시 입력으로 동작 확인\n",
    "hist = np.array([\n",
    "  [ 0.3047, -0.0590, 0.2224 ,  0.0041,  0.9997,  0.0149,  0.0179,  1.0000, 0.3047, -0.0590, 0.02198],\n",
    "  [0.3028, -0.0620,  0.2207,  0.0081,  0.9987,  0.0268,  0.0416,  1.0000, 0.3047, -0.0590, 0.0198],\n",
    "  [0.3001, -0.0655,  0.2198,  0.0122,  0.9970,  0.0366,  0.0671,  1.0000, 0.3047, -0.0590, 0.0198],\n",
    "], dtype=np.float32)\n",
    "act8 = predict_action(model, x_norm_re, y_norm_re, hist)\n",
    "print(\"pred action(8):\", act8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e7c380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 001  val_mse 4.127453e-03\n",
      "epoch 002  val_mse 4.082528e-03\n",
      "epoch 003  val_mse 3.998474e-03\n",
      "epoch 004  val_mse 4.136385e-03\n",
      "epoch 005  val_mse 3.999661e-03\n",
      "epoch 006  val_mse 3.890003e-03\n",
      "epoch 007  val_mse 3.968273e-03\n",
      "epoch 008  val_mse 3.875523e-03\n",
      "epoch 009  val_mse 3.986794e-03\n",
      "epoch 010  val_mse 3.745388e-03\n",
      "epoch 011  val_mse 3.722920e-03\n",
      "epoch 012  val_mse 3.911222e-03\n",
      "epoch 013  val_mse 3.822294e-03\n",
      "epoch 014  val_mse 3.762618e-03\n",
      "epoch 015  val_mse 3.894726e-03\n",
      "epoch 016  val_mse 3.800425e-03\n",
      "epoch 017  val_mse 3.833497e-03\n",
      "epoch 018  val_mse 3.471099e-03\n",
      "epoch 019  val_mse 4.761554e-03\n",
      "epoch 020  val_mse 3.698392e-03\n",
      "epoch 021  val_mse 3.710360e-03\n",
      "epoch 022  val_mse 3.618299e-03\n",
      "epoch 023  val_mse 3.827658e-03\n",
      "epoch 024  val_mse 3.680760e-03\n",
      "epoch 025  val_mse 3.349911e-03\n",
      "epoch 026  val_mse 3.264487e-03\n",
      "epoch 027  val_mse 3.605328e-03\n",
      "epoch 028  val_mse 3.521723e-03\n",
      "epoch 029  val_mse 3.729552e-03\n",
      "epoch 030  val_mse 3.562501e-03\n",
      "epoch 031  val_mse 3.619682e-03\n",
      "epoch 032  val_mse 3.723929e-03\n",
      "epoch 033  val_mse 3.748094e-03\n",
      "epoch 034  val_mse 3.613173e-03\n",
      "epoch 035  val_mse 3.637287e-03\n",
      "epoch 036  val_mse 4.006518e-03\n",
      "epoch 037  val_mse 3.629087e-03\n",
      "epoch 038  val_mse 4.097358e-03\n",
      "epoch 039  val_mse 3.498856e-03\n",
      "epoch 040  val_mse 3.389023e-03\n",
      "epoch 041  val_mse 3.517732e-03\n",
      "epoch 042  val_mse 3.131710e-03\n",
      "epoch 043  val_mse 3.429723e-03\n",
      "epoch 044  val_mse 3.689404e-03\n",
      "epoch 045  val_mse 3.168843e-03\n",
      "epoch 046  val_mse 3.288258e-03\n",
      "epoch 047  val_mse 3.487154e-03\n",
      "epoch 048  val_mse 3.699573e-03\n",
      "epoch 049  val_mse 3.502579e-03\n",
      "epoch 050  val_mse 3.542807e-03\n",
      "학습 완료. best val MSE: 0.0031317102430152358\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "# Imitation Learning: s_{t-3:t-1} -> a_t(= s_t[:8])\n",
    "# - 입력: (3, 11), 출력: (8,)\n",
    "# - 초기 t<3 규칙: t=0,1,2 모두 복제 규칙 적용\n",
    "# - 정규화: train split 통계로 표준화(입력 11, 출력 8 각각 별도)\n",
    "\n",
    "import os, json, random, math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# -------------------------\n",
    "# 설정\n",
    "# -------------------------\n",
    "PATH = \"merged_success_episodes.npz\"\n",
    "VAL_RATIO = 0.1\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 50\n",
    "LR = 1e-3\n",
    "HIDDEN = 128\n",
    "SEED = 42\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# -------------------------\n",
    "# 유틸\n",
    "# -------------------------\n",
    "def ensure_Tx11(arr):\n",
    "    a = np.asarray(arr)\n",
    "    if a.ndim == 1 and a.shape[0] == 11:\n",
    "        return a[None, :]\n",
    "    if a.ndim == 2 and a.shape[1] == 11:\n",
    "        return a\n",
    "    if a.ndim == 2 and a.shape[0] == 11:\n",
    "        return a.T\n",
    "    raise ValueError(f\"shape must be (T,11) or (11,T), got {a.shape}\")\n",
    "\n",
    "def make_window(ep, t):\n",
    "    \"\"\"규칙대로 (3,11) 윈도우 생성. ep: (T,11)\"\"\"\n",
    "    if t == 0:\n",
    "        w = np.stack([ep[0], ep[0], ep[0]], axis=0)\n",
    "    elif t == 1:\n",
    "        w = np.stack([ep[0], ep[0], ep[0]], axis=0)  # 지시사항: 2번째 스텝 예측도 1번째 3번 복제\n",
    "    elif t == 2:\n",
    "        w = np.stack([ep[0], ep[1], ep[1]], axis=0)  # 지시사항: 1번째 1회 + 2번째 2회\n",
    "    else:\n",
    "        w = ep[t-3:t, :]\n",
    "    return w  # (3,11)\n",
    "\n",
    "class ColumnStandardizer:\n",
    "    def __init__(self, dim):\n",
    "        self.mu = np.zeros(dim, dtype=np.float64)\n",
    "        self.std = np.ones(dim, dtype=np.float64)\n",
    "\n",
    "    def fit(self, X):\n",
    "        # X: (N, dim) or (..., dim)\n",
    "        X2 = X.reshape(-1, X.shape[-1]).astype(np.float64)\n",
    "        self.mu = X2.mean(axis=0)\n",
    "        self.std = X2.std(axis=0)\n",
    "        self.std[self.std < 1e-8] = 1.0  # 분산 0 보호\n",
    "\n",
    "    def transform(self, X):\n",
    "        return (X - self.mu) / self.std\n",
    "\n",
    "    def inverse(self, Xn):\n",
    "        return Xn * self.std + self.mu\n",
    "\n",
    "    def state(self):\n",
    "        return {\"mu\": self.mu.tolist(), \"std\": self.std.tolist()}\n",
    "\n",
    "class ILDataset(Dataset):\n",
    "    def __init__(self, npz, keys):\n",
    "        self.samples = []\n",
    "        for k in keys:\n",
    "            ep = ensure_Tx11(npz[k])\n",
    "            T = ep.shape[0]\n",
    "            for t in range(T):\n",
    "                y = ep[t, :8]\n",
    "                X = make_window(ep, t)\n",
    "                self.samples.append((X, y))\n",
    "\n",
    "    def __len__(self): return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X, y = self.samples[idx]\n",
    "        X = torch.from_numpy(X.astype(np.float32))  # (3,11)\n",
    "        y = torch.from_numpy(y.astype(np.float32))  # (8,)\n",
    "        return X, y\n",
    "\n",
    "class GRUPolicy(nn.Module):\n",
    "    # 입력: (B,3,11) -> GRU -> head -> (B,8)\n",
    "    def __init__(self, in_dim=11, hidden=128, out_dim=8, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_size=in_dim, hidden_size=hidden, num_layers=num_layers, batch_first=True)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden, out_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # x: (B,3,11)\n",
    "        h, _ = self.gru(x)\n",
    "        last = h[:, -1, :]\n",
    "        return self.head(last)  # (B,8)\n",
    "\n",
    "class MLPPolicy(nn.Module):\n",
    "    # 입력: (B,3,11) -> flatten -> MLP -> (B,8)\n",
    "    def __init__(self, in_dim=11, win=3, hidden=256, out_dim=8):\n",
    "        super().__init__()\n",
    "        self.win = win\n",
    "        self.in_dim = in_dim\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim*win, hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden, out_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # x: (B,3,11)\n",
    "        B = x.size(0)\n",
    "        x = x.view(B, self.win * self.in_dim)  # (B,33)\n",
    "        return self.net(x)  # (B,8)\n",
    "\n",
    "# -------------------------\n",
    "# 데이터 로드 및 split\n",
    "# -------------------------\n",
    "npz = np.load(PATH, allow_pickle=True)\n",
    "keys = sorted([k for k in npz.files if k.startswith(\"episode\")])\n",
    "if not keys:\n",
    "    raise RuntimeError(\"episode### 키가 없음\")\n",
    "\n",
    "# 에피소드 단위 분할\n",
    "n_val = max(1, int(len(keys) * VAL_RATIO))\n",
    "random.shuffle(keys)\n",
    "val_keys = sorted(keys[:n_val])\n",
    "train_keys = sorted(keys[n_val:])\n",
    "\n",
    "# 정규화 통계 추출을 위해 train 전부 펼치기\n",
    "train_states = []\n",
    "train_targets = []\n",
    "for k in train_keys:\n",
    "    ep = ensure_Tx11(npz[k])\n",
    "    T = ep.shape[0]\n",
    "    # 입력용: 윈도우 3개 모두 포함하므로, 먼저 원본 분포 기준으로 통계 계산\n",
    "    # 입력 정규화는 state 컬럼별 통계 필요 → 원본 ep 전 구간 사용\n",
    "    train_states.append(ep)           # (T,11)\n",
    "    train_targets.append(ep[:, :8])   # (T,8)\n",
    "\n",
    "train_states = np.concatenate(train_states, axis=0)  # (S,11)\n",
    "train_targets = np.concatenate(train_targets, axis=0)  # (S,8)\n",
    "\n",
    "x_norm = ColumnStandardizer(dim=11)\n",
    "y_norm = ColumnStandardizer(dim=8)\n",
    "x_norm.fit(train_states)\n",
    "y_norm.fit(train_targets)\n",
    "\n",
    "# 데이터셋 생성\n",
    "train_ds = ILDataset(npz, train_keys)\n",
    "val_ds   = ILDataset(npz, val_keys)\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "\n",
    "# -------------------------\n",
    "# 학습 루프\n",
    "# -------------------------\n",
    "#model = GRUPolicy(in_dim=11, hidden=HIDDEN, out_dim=8).to(DEVICE)\n",
    "model = MLPPolicy(in_dim=11, win=3, hidden=256, out_dim=8).to(DEVICE)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    tot, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in val_loader:\n",
    "            X = X.to(DEVICE)   # (B,3,11)\n",
    "            y = y.to(DEVICE)   # (B,8)\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "            bs = X.size(0)\n",
    "            tot += loss.item() * bs\n",
    "            n += bs\n",
    "    return tot / max(n, 1)\n",
    "\n",
    "best_val = math.inf\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    for X, y in train_loader:\n",
    "        X = X.to(DEVICE)   # (B,3,11)\n",
    "        y = y.to(DEVICE)   # (B,8)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    val_mse = evaluate()\n",
    "    print(f\"epoch {epoch:03d}  val_mse {val_mse:.6e}\")\n",
    "    if val_mse < best_val:\n",
    "        best_val = val_mse\n",
    "        torch.save({\n",
    "            \"model\": model.state_dict(),\n",
    "            \"cfg\": {\"arch\": \"GRU\", \"hidden\": HIDDEN}  # 필요시 메타만 저장\n",
    "        }, \"il_gru_best5_nonnorm.pt\")\n",
    "\n",
    "print(\"학습 완료. best val MSE:\", best_val)\n",
    "\n",
    "# -------------------------\n",
    "# 추론 함수 예시\n",
    "# -------------------------\n",
    "def load_norm(state):\n",
    "    sd_x = np.array(state[\"x_norm\"][\"mu\"], dtype=np.float64)\n",
    "    sd_y = np.array(state[\"y_norm\"][\"mu\"], dtype=np.float64)  # not used here\n",
    "    # 이미 ColumnStandardizer 상태 저장했으므로 그대로 복원\n",
    "    nx = ColumnStandardizer(11)\n",
    "    ny = ColumnStandardizer(8)\n",
    "    nx.mu = np.array(state[\"x_norm\"][\"mu\"], dtype=np.float64)\n",
    "    nx.std = np.array(state[\"x_norm\"][\"std\"], dtype=np.float64)\n",
    "    ny.mu = np.array(state[\"y_norm\"][\"mu\"], dtype=np.float64)\n",
    "    ny.std = np.array(state[\"y_norm\"][\"std\"], dtype=np.float64)\n",
    "    return nx, ny\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_action(model, history_ks):\n",
    "    hist = ensure_Tx11(history_ks)\n",
    "    if hist.shape[0] == 1:\n",
    "        X = np.stack([hist[0], hist[0], hist[0]], axis=0)\n",
    "    elif hist.shape[0] == 2:\n",
    "        X = np.stack([hist[0], hist[1], hist[1]], axis=0)\n",
    "    else:\n",
    "        X = hist[-3:, :]\n",
    "\n",
    "    xt = torch.from_numpy(X.astype(np.float32))[None, ...].to(DEVICE)  # (1,3,11)\n",
    "    y  = model(xt)[0].detach().cpu().numpy()                            # (8,)\n",
    "    return y\n",
    "\n",
    "# 저장된 베스트 체크포인트 복원 예시\n",
    "# ckpt = torch.load(\"il_gru_best5_nonnorm.pt\", map_location=DEVICE)\n",
    "\n",
    "# model = MLPPolicy(in_dim=11, win=3, hidden=256, out_dim=8).to(DEVICE)\n",
    "# model.load_state_dict(ckpt[\"model\"])\n",
    "\n",
    "# --- 체크포인트 로드 ---\n",
    "# ckpt = torch.load(\"il_gru_best_nonnorm.pt\", map_location=DEVICE, weights_only=True)\n",
    "# model = GRUPolicy(in_dim=11, hidden=HIDDEN, out_dim=8).to(DEVICE)\n",
    "# model.load_state_dict(ckpt[\"model\"], strict=True)\n",
    "# model.eval()\n",
    "\n",
    "\n",
    "# 예시 입력으로 동작 확인\n",
    "# hist = np.array([\n",
    "#   [0.2955, -0.0532, 0.1080, -0.0028, 1.0029, -0.0139, -0.0057, -1.0000, 0.1029, -0.2139, -0.0357],\n",
    "#   [0.2890, -0.1274, 0.0823,  0.0184, 0.9880, -0.0451,  0.0118, -1.0000, 0.0229, -0.7131, -0.3056],\n",
    "#   [0.2899, -0.1282, 0.0969,  0.0253, 0.9847, -0.0472,  0.0422,  1.0000, -0.0249, -1.0109, -0.0057],\n",
    "# ], dtype=np.float32)\n",
    "# act8 = predict_action(model, x_norm_re, y_norm_re, hist)\n",
    "# print(\"pred action(8):\", act8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e68942f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 001  val_mse 4.274924e-03\n",
      "epoch 002  val_mse 4.217944e-03\n",
      "epoch 003  val_mse 4.087998e-03\n",
      "epoch 004  val_mse 4.007146e-03\n",
      "epoch 005  val_mse 3.992849e-03\n",
      "epoch 006  val_mse 3.972497e-03\n",
      "epoch 007  val_mse 3.968710e-03\n",
      "epoch 008  val_mse 3.546990e-03\n",
      "epoch 009  val_mse 4.418097e-03\n",
      "epoch 010  val_mse 3.767432e-03\n",
      "epoch 011  val_mse 3.777175e-03\n",
      "epoch 012  val_mse 3.857196e-03\n",
      "epoch 013  val_mse 3.782600e-03\n",
      "epoch 014  val_mse 3.731214e-03\n",
      "epoch 015  val_mse 3.726845e-03\n",
      "epoch 016  val_mse 3.544882e-03\n",
      "epoch 017  val_mse 3.273936e-03\n",
      "epoch 018  val_mse 3.567103e-03\n",
      "epoch 019  val_mse 3.514280e-03\n",
      "epoch 020  val_mse 3.746354e-03\n",
      "epoch 021  val_mse 3.194688e-03\n",
      "epoch 022  val_mse 3.611814e-03\n",
      "epoch 023  val_mse 3.440305e-03\n",
      "epoch 024  val_mse 3.154549e-03\n",
      "epoch 025  val_mse 3.591808e-03\n",
      "epoch 026  val_mse 3.111332e-03\n",
      "epoch 027  val_mse 2.895385e-03\n",
      "epoch 028  val_mse 3.082905e-03\n",
      "epoch 029  val_mse 3.246415e-03\n",
      "epoch 030  val_mse 2.922798e-03\n",
      "epoch 031  val_mse 3.342605e-03\n",
      "epoch 032  val_mse 2.837218e-03\n",
      "epoch 033  val_mse 3.247008e-03\n",
      "epoch 034  val_mse 3.375592e-03\n",
      "epoch 035  val_mse 2.639445e-03\n",
      "epoch 036  val_mse 3.112469e-03\n",
      "epoch 037  val_mse 2.879137e-03\n",
      "epoch 038  val_mse 2.687213e-03\n",
      "epoch 039  val_mse 2.556994e-03\n",
      "epoch 040  val_mse 2.549966e-03\n",
      "epoch 041  val_mse 3.170103e-03\n",
      "epoch 042  val_mse 3.026233e-03\n",
      "epoch 043  val_mse 2.595399e-03\n",
      "epoch 044  val_mse 2.996970e-03\n",
      "epoch 045  val_mse 3.004590e-03\n",
      "epoch 046  val_mse 3.452056e-03\n",
      "epoch 047  val_mse 2.717359e-03\n",
      "epoch 048  val_mse 2.562501e-03\n",
      "epoch 049  val_mse 2.449379e-03\n",
      "epoch 050  val_mse 3.252350e-03\n",
      "학습 완료. best val MSE: 0.0024493785513064535\n"
     ]
    }
   ],
   "source": [
    "#!# for adaptive window\n",
    "\n",
    "import os, json, random, math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# -------------------------\n",
    "# 설정\n",
    "# -------------------------\n",
    "PATH = \"merged_success_episodes.npz\"\n",
    "VAL_RATIO = 0.1\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 50\n",
    "LR = 1e-3\n",
    "HIDDEN = 128\n",
    "SEED = 42\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "WIN = 7\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# -------------------------\n",
    "# 유틸\n",
    "# -------------------------\n",
    "def ensure_Tx11(arr):\n",
    "    a = np.asarray(arr)\n",
    "    if a.ndim == 1 and a.shape[0] == 11:\n",
    "        return a[None, :]\n",
    "    if a.ndim == 2 and a.shape[1] == 11:\n",
    "        return a\n",
    "    if a.ndim == 2 and a.shape[0] == 11:\n",
    "        return a.T\n",
    "    raise ValueError(f\"shape must be (T,11) or (11,T), got {a.shape}\")\n",
    "\n",
    "def make_window(ep, t, win=WIN):\n",
    "    \"\"\"\n",
    "    ep: (T, 11), t: 예측 시점\n",
    "    규칙: ep[max(0,t-win):t]을 가져오고, 길이가 win보다 작으면 마지막 행을 반복해 오른쪽 패딩.\n",
    "    t=0이면 ep[0]을 win번 복제.\n",
    "    결과 shape: (win, 11)\n",
    "    \"\"\"\n",
    "    if t <= 0:\n",
    "        w = np.repeat(ep[0:1, :], win, axis=0)\n",
    "        return w\n",
    "    seq = ep[max(0, t - win): t, :]        # 과거 시퀀스\n",
    "    if seq.shape[0] == 0:\n",
    "        base = ep[0:1, :]\n",
    "    else:\n",
    "        base = seq\n",
    "    if base.shape[0] < win:\n",
    "        pad = np.repeat(base[-1:, :], win - base.shape[0], axis=0)\n",
    "        w = np.concatenate([base, pad], axis=0)\n",
    "    else:\n",
    "        w = base\n",
    "    return w  # (win, 11)\n",
    "\n",
    "class ColumnStandardizer:\n",
    "    def __init__(self, dim):\n",
    "        self.mu = np.zeros(dim, dtype=np.float64)\n",
    "        self.std = np.ones(dim, dtype=np.float64)\n",
    "\n",
    "    def fit(self, X):\n",
    "        # X: (N, dim) or (..., dim)\n",
    "        X2 = X.reshape(-1, X.shape[-1]).astype(np.float64)\n",
    "        self.mu = X2.mean(axis=0)\n",
    "        self.std = X2.std(axis=0)\n",
    "        self.std[self.std < 1e-8] = 1.0  # 분산 0 보호\n",
    "\n",
    "    def transform(self, X):\n",
    "        return (X - self.mu) / self.std\n",
    "\n",
    "    def inverse(self, Xn):\n",
    "        return Xn * self.std + self.mu\n",
    "\n",
    "    def state(self):\n",
    "        return {\"mu\": self.mu.tolist(), \"std\": self.std.tolist()}\n",
    "\n",
    "class ILDataset(Dataset):\n",
    "    def __init__(self, npz, keys):\n",
    "        self.samples = []\n",
    "        for k in keys:\n",
    "            ep = ensure_Tx11(npz[k])\n",
    "            T = ep.shape[0]\n",
    "            for t in range(T):\n",
    "                y = ep[t, :8]\n",
    "                X = make_window(ep, t, win=WIN)  # (WIN,11)\n",
    "                self.samples.append((X, y))\n",
    "\n",
    "    def __len__(self): return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X, y = self.samples[idx]\n",
    "        X = torch.from_numpy(X.astype(np.float32))  # (3,11)\n",
    "        y = torch.from_numpy(y.astype(np.float32))  # (8,)\n",
    "        return X, y\n",
    "\n",
    "class GRUPolicy(nn.Module):\n",
    "    # 입력: (B,3,11) -> GRU -> head -> (B,8)\n",
    "    def __init__(self, in_dim=11, hidden=128, out_dim=8, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_size=in_dim, hidden_size=hidden, num_layers=num_layers, batch_first=True)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden, out_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # x: (B,3,11)\n",
    "        h, _ = self.gru(x)\n",
    "        last = h[:, -1, :]\n",
    "        return self.head(last)  # (B,8)\n",
    "\n",
    "class MLPPolicy(nn.Module):\n",
    "    def __init__(self, in_dim=11, win=WIN, hidden=256, out_dim=8):\n",
    "        super().__init__()\n",
    "        self.win = win\n",
    "        self.in_dim = in_dim\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim * win, hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden, out_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # x: (B,WIN,11)\n",
    "        B = x.size(0)\n",
    "        x = x.view(B, self.win * self.in_dim)  # (B, 11*WIN)\n",
    "        return self.net(x)\n",
    "\n",
    "# -------------------------\n",
    "# 데이터 로드 및 split\n",
    "# -------------------------\n",
    "npz = np.load(PATH, allow_pickle=True)\n",
    "keys = sorted([k for k in npz.files if k.startswith(\"episode\")])\n",
    "if not keys:\n",
    "    raise RuntimeError(\"episode### 키가 없음\")\n",
    "\n",
    "# 에피소드 단위 분할\n",
    "n_val = max(1, int(len(keys) * VAL_RATIO))\n",
    "random.shuffle(keys)\n",
    "val_keys = sorted(keys[:n_val])\n",
    "train_keys = sorted(keys[n_val:])\n",
    "\n",
    "# 정규화 통계 추출을 위해 train 전부 펼치기\n",
    "train_states = []\n",
    "train_targets = []\n",
    "for k in train_keys:\n",
    "    ep = ensure_Tx11(npz[k])\n",
    "    T = ep.shape[0]\n",
    "    # 입력용: 윈도우 3개 모두 포함하므로, 먼저 원본 분포 기준으로 통계 계산\n",
    "    # 입력 정규화는 state 컬럼별 통계 필요 → 원본 ep 전 구간 사용\n",
    "    train_states.append(ep)           # (T,11)\n",
    "    train_targets.append(ep[:, :8])   # (T,8)\n",
    "\n",
    "train_states = np.concatenate(train_states, axis=0)  # (S,11)\n",
    "train_targets = np.concatenate(train_targets, axis=0)  # (S,8)\n",
    "\n",
    "x_norm = ColumnStandardizer(dim=11)\n",
    "y_norm = ColumnStandardizer(dim=8)\n",
    "x_norm.fit(train_states)\n",
    "y_norm.fit(train_targets)\n",
    "\n",
    "# 데이터셋 생성\n",
    "train_ds = ILDataset(npz, train_keys)\n",
    "val_ds   = ILDataset(npz, val_keys)\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "\n",
    "# -------------------------\n",
    "# 학습 루프\n",
    "# -------------------------\n",
    "model = GRUPolicy(in_dim=11, hidden=HIDDEN, out_dim=8).to(DEVICE)\n",
    "#model = MLPPolicy(in_dim=11, win=WIN, hidden=256, out_dim=8).to(DEVICE)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    tot, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in val_loader:\n",
    "            X = X.to(DEVICE)   # (B,3,11)\n",
    "            y = y.to(DEVICE)   # (B,8)\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "            bs = X.size(0)\n",
    "            tot += loss.item() * bs\n",
    "            n += bs\n",
    "    return tot / max(n, 1)\n",
    "\n",
    "best_val = math.inf\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    for X, y in train_loader:\n",
    "        X = X.to(DEVICE)   # (B,3,11)\n",
    "        y = y.to(DEVICE)   # (B,8)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    val_mse = evaluate()\n",
    "    print(f\"epoch {epoch:03d}  val_mse {val_mse:.6e}\")\n",
    "    if val_mse < best_val:\n",
    "        best_val = val_mse\n",
    "        torch.save({\n",
    "            \"model\": model.state_dict(),\n",
    "            \"cfg\": {\"arch\": \"GRU\", \"hidden\": HIDDEN}  # 필요시 메타만 저장\n",
    "        }, \"il_gru_best7_nonnorm.pt\")\n",
    "\n",
    "print(\"학습 완료. best val MSE:\", best_val)\n",
    "\n",
    "# -------------------------\n",
    "# 추론 함수 예시\n",
    "# -------------------------\n",
    "def load_norm(state):\n",
    "    sd_x = np.array(state[\"x_norm\"][\"mu\"], dtype=np.float64)\n",
    "    sd_y = np.array(state[\"y_norm\"][\"mu\"], dtype=np.float64)  # not used here\n",
    "    # 이미 ColumnStandardizer 상태 저장했으므로 그대로 복원\n",
    "    nx = ColumnStandardizer(11)\n",
    "    ny = ColumnStandardizer(8)\n",
    "    nx.mu = np.array(state[\"x_norm\"][\"mu\"], dtype=np.float64)\n",
    "    nx.std = np.array(state[\"x_norm\"][\"std\"], dtype=np.float64)\n",
    "    ny.mu = np.array(state[\"y_norm\"][\"mu\"], dtype=np.float64)\n",
    "    ny.std = np.array(state[\"y_norm\"][\"std\"], dtype=np.float64)\n",
    "    return nx, ny\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_action(model, history_ks):\n",
    "    hist = ensure_Tx11(history_ks)          # (T,11)\n",
    "    # 과거 T에서 t 시점은 마지막 행으로 간주. make_window 규칙 재사용:\n",
    "    X = make_window(hist, t=hist.shape[0], win=WIN)  # (WIN,11)\n",
    "    xt = torch.from_numpy(X.astype(np.float32))[None, ...].to(DEVICE)  # (1,WIN,11)\n",
    "    y  = model(xt)[0].detach().cpu().numpy()  # (8,)\n",
    "    return y\n",
    "\n",
    "# 저장된 베스트 체크포인트 복원 예시\n",
    "# ckpt = torch.load(\"il_gru_best5_nonnorm.pt\", map_location=DEVICE)\n",
    "\n",
    "# model = MLPPolicy(in_dim=11, win=3, hidden=256, out_dim=8).to(DEVICE)\n",
    "# model.load_state_dict(ckpt[\"model\"])\n",
    "\n",
    "# --- 체크포인트 로드 ---\n",
    "# ckpt = torch.load(\"il_gru_best_nonnorm.pt\", map_location=DEVICE, weights_only=True)\n",
    "# model = GRUPolicy(in_dim=11, hidden=HIDDEN, out_dim=8).to(DEVICE)\n",
    "# model.load_state_dict(ckpt[\"model\"], strict=True)\n",
    "# model.eval()\n",
    "\n",
    "\n",
    "# 예시 입력으로 동작 확인\n",
    "# hist = np.array([\n",
    "#   [0.2955, -0.0532, 0.1080, -0.0028, 1.0029, -0.0139, -0.0057, -1.0000, 0.1029, -0.2139, -0.0357],\n",
    "#   [0.2890, -0.1274, 0.0823,  0.0184, 0.9880, -0.0451,  0.0118, -1.0000, 0.0229, -0.7131, -0.3056],\n",
    "#   [0.2899, -0.1282, 0.0969,  0.0253, 0.9847, -0.0472,  0.0422,  1.0000, -0.0249, -1.0109, -0.0057],\n",
    "# ], dtype=np.float32)\n",
    "# act8 = predict_action(model, x_norm_re, y_norm_re, hist)\n",
    "# print(\"pred action(8):\", act8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "770c2aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved with 1462 episodes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "root_dir = \"success_data_raw\"\n",
    "episodes = {}\n",
    "\n",
    "# 디렉토리 순회\n",
    "for dirname in sorted(os.listdir(root_dir)):\n",
    "    match = re.match(r\"success_episode(\\d+)_steps\\d+\", dirname)\n",
    "    if not match:\n",
    "        continue\n",
    "    ep_num = int(match.group(1))  # episode 번호\n",
    "    ep_dir = os.path.join(root_dir, dirname)\n",
    "    file_path = os.path.join(ep_dir, \"robot_state.npz\")\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Missing: {file_path}\")\n",
    "        continue\n",
    "\n",
    "    data = np.load(file_path)\n",
    "    EE_pose = data[\"EE_pose\"]              # (T, 7)\n",
    "    obs = data[\"obs\"]                      # (T, 29)\n",
    "\n",
    "    merged = np.concatenate([\n",
    "        EE_pose,                           # (T, 7)\n",
    "        obs[:, -1:].astype(np.float32),    # 마지막 column (T, 1)\n",
    "        obs[:, 18:21].astype(np.float32)   # col 18~20 (T, 3)\n",
    "    ], axis=1)                             # → (T, 11)\n",
    "\n",
    "    episodes[f\"episode{ep_num:04d}\"] = merged.astype(np.float32)\n",
    "\n",
    "# 저장\n",
    "np.savez_compressed(\"all_success_episodes.npz\", **episodes)\n",
    "print(\"Saved with\", len(episodes), \"episodes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "27007b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes in file: ['episode1000', 'episode1001', 'episode1002', 'episode1003', 'episode1004', 'episode1005', 'episode1006', 'episode1007', 'episode1008', 'episode1009'] ...\n",
      "Total episodes: 1462\n",
      "episode0001 shape: (329, 11)\n",
      "[[ 3.0280018e-01 -5.6915428e-02  6.2759626e-01  6.3736957e-07\n",
      "   9.9999994e-01 -3.2587252e-06  3.8592243e-06  1.0000000e+00\n",
      "   4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      " [ 3.0280003e-01 -5.6915559e-02  6.2759638e-01  7.0907276e-07\n",
      "   9.9999988e-01 -3.2411465e-06  3.8638618e-06  1.0000000e+00\n",
      "   4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      " [ 3.0280015e-01 -5.6915652e-02  6.2759638e-01  6.7365897e-07\n",
      "   9.9999994e-01 -3.3317756e-06  3.9488505e-06 -1.0000000e+00\n",
      "   4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      " [ 3.0280009e-01 -5.6915496e-02  6.2759638e-01  7.1186969e-07\n",
      "   1.0000000e+00 -3.1691920e-06  3.8538697e-06 -1.0000000e+00\n",
      "   4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      " [ 3.0280015e-01 -5.6915689e-02  6.2759638e-01  6.7365897e-07\n",
      "   9.9999994e-01 -3.3317756e-06  3.9488505e-06 -1.0000000e+00\n",
      "   4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      " [ 3.0280015e-01 -5.6915578e-02  6.2759638e-01  5.9453532e-07\n",
      "   9.9999988e-01 -3.1691727e-06  3.8505723e-06 -1.0000000e+00\n",
      "   4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      " [ 3.0280015e-01 -5.6915406e-02  6.2759638e-01  5.9451713e-07\n",
      "   1.0000000e+00 -2.9544640e-06  3.9037595e-06 -1.0000000e+00\n",
      "   4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      " [ 3.0280018e-01 -5.6915492e-02  6.2759638e-01  8.0683503e-07\n",
      "   1.0000000e+00 -2.9546095e-06  3.9131410e-06 -1.0000000e+00\n",
      "   4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      " [ 3.0280006e-01 -5.6915518e-02  6.2759590e-01  5.9184322e-07\n",
      "   1.0000000e+00 -2.9492835e-06  3.5335936e-06 -1.0000000e+00\n",
      "   4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      " [ 3.0280006e-01 -5.6915436e-02  6.2759590e-01  5.7040802e-07\n",
      "   9.9999988e-01 -2.8185298e-06  3.5828068e-06 -1.0000000e+00\n",
      "   4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      " [ 3.0280006e-01 -5.6915436e-02  6.2759590e-01  5.7040802e-07\n",
      "   9.9999988e-01 -2.8185298e-06  3.5828068e-06 -1.0000000e+00\n",
      "   4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      " [ 3.0280006e-01 -5.6915440e-02  6.2759590e-01  5.6296676e-07\n",
      "   1.0000000e+00 -2.7761739e-06  3.5563858e-06 -1.0000000e+00\n",
      "   4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      " [ 3.0280000e-01 -5.6915510e-02  6.2759590e-01  7.3247543e-07\n",
      "   1.0000000e+00 -2.7751262e-06  3.4805448e-06 -1.0000000e+00\n",
      "   4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      " [ 3.0279997e-01 -5.6915406e-02  6.2759590e-01  6.1793980e-07\n",
      "   1.0000000e+00 -2.5593795e-06  3.4591967e-06 -1.0000000e+00\n",
      "   4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      " [ 3.0280000e-01 -5.6915499e-02  6.2759590e-01  5.7788975e-07\n",
      "   1.0000000e+00 -2.5298682e-06  3.4807308e-06 -1.0000000e+00\n",
      "   4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      " [ 3.0280000e-01 -5.6915499e-02  6.2759590e-01  5.7788975e-07\n",
      "   1.0000000e+00 -2.5298682e-06  3.4807308e-06 -1.0000000e+00\n",
      "   4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      " [ 3.0280006e-01 -5.6915391e-02  6.2759614e-01  6.2910203e-07\n",
      "   9.9999994e-01 -2.3985906e-06  3.4950458e-06 -1.0000000e+00\n",
      "   4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      " [ 3.0279994e-01 -5.6915484e-02  6.2759602e-01  4.2238366e-07\n",
      "   1.0000000e+00 -2.3559728e-06  3.4480729e-06 -1.0000000e+00\n",
      "   4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      " [ 3.0279994e-01 -5.6915484e-02  6.2759602e-01  4.2238366e-07\n",
      "   1.0000000e+00 -2.3559728e-06  3.4480729e-06 -1.0000000e+00\n",
      "   4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      " [ 3.0280006e-01 -5.6915373e-02  6.2759590e-01  4.6334884e-07\n",
      "   1.0000000e+00 -2.1828632e-06  3.4732154e-06 -1.0000000e+00\n",
      "   4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      " [ 3.0280006e-01 -5.6915563e-02  6.2759602e-01  4.5494875e-07\n",
      "   9.9999988e-01 -2.3273444e-06  3.5338858e-06 -1.0000000e+00\n",
      "   4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      " [ 3.0280006e-01 -5.6915563e-02  6.2759602e-01  4.5494875e-07\n",
      "   9.9999988e-01 -2.3273444e-06  3.5338858e-06 -1.0000000e+00\n",
      "   4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      " [ 3.0280006e-01 -5.6915563e-02  6.2759602e-01  4.5494875e-07\n",
      "   9.9999988e-01 -2.3273444e-06  3.5338858e-06 -1.0000000e+00\n",
      "   4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      " [ 3.0280006e-01 -5.6915607e-02  6.2759602e-01  2.3422081e-07\n",
      "   1.0000000e+00 -2.2864535e-06  3.6135559e-06 -1.0000000e+00\n",
      "   4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      " [ 3.0280006e-01 -5.6915607e-02  6.2759602e-01  2.3422081e-07\n",
      "   1.0000000e+00 -2.2864535e-06  3.6135559e-06 -1.0000000e+00\n",
      "   4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      " [ 3.0280006e-01 -5.6915607e-02  6.2759602e-01  2.3422081e-07\n",
      "   1.0000000e+00 -2.2864535e-06  3.6135559e-06 -1.0000000e+00\n",
      "   4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      " [ 3.0280003e-01 -5.6915853e-02  6.2759626e-01  3.9535666e-07\n",
      "   9.9999994e-01 -2.5601944e-06  3.5168605e-06 -1.0000000e+00\n",
      "   4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      " [ 3.0476150e-01 -5.8437835e-02  6.2238431e-01  9.1318041e-05\n",
      "   9.9975663e-01  1.2026275e-02  1.8492438e-02  1.0000000e+00\n",
      "   4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      " [ 3.0275521e-01 -6.1926670e-02  6.2058020e-01  2.7275644e-04\n",
      "   9.9886614e-01  2.0756803e-02  4.2840101e-02  1.0000000e+00\n",
      "   4.0991434e-01  4.4602789e-03  5.3000380e-04]\n",
      " [ 2.9985350e-01 -6.6377878e-02  6.1967075e-01  9.5906667e-04\n",
      "   9.9723947e-01  2.7530653e-02  6.8952799e-02  1.0000000e+00\n",
      "   4.0991434e-01  4.4602789e-03  5.3000380e-04]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 파일 로드\n",
    "data = np.load(\"all_success_episodes.npz\", allow_pickle=True)\n",
    "\n",
    "# 키 확인\n",
    "print(\"Episodes in file:\", list(data.keys())[:10], \"...\")  # 처음 10개만 출력\n",
    "print(\"Total episodes:\", len(data.keys()))\n",
    "\n",
    "# 특정 episode 확인\n",
    "ep_key = \"episode0001\"\n",
    "print(ep_key, \"shape:\", data[ep_key].shape)\n",
    "\n",
    "# 데이터 일부 확인\n",
    "print(data[ep_key][0:30])  # 앞 5 step 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a03d4b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episodes: 1462\n",
      "trimmed episodes: 1461\n",
      "total removed timesteps: 4246\n",
      "saved -> all_success_episodes_trimmed.npz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "in_path  = \"all_success_episodes.npz\"\n",
    "out_path = \"all_success_episodes_trimmed.npz\"\n",
    "\n",
    "data = np.load(in_path, allow_pickle=True)\n",
    "out  = {}\n",
    "changed, removed_total = 0, 0\n",
    "\n",
    "def is_neg_one(x, atol=1e-6):\n",
    "    return np.isclose(x, -1.0, atol=atol)\n",
    "\n",
    "def is_pos_one(x, atol=1e-6):\n",
    "    return np.isclose(x,  1.0, atol=atol)\n",
    "\n",
    "for k in data.files:\n",
    "    traj = data[k]                  # (T, 11)\n",
    "    last = traj[:, -4]              # (T,)\n",
    "    T = len(last)\n",
    "\n",
    "    idx = None\n",
    "    max_i = min(T - 2, 49)          # 전이 검사는 최대 50 step 구간만\n",
    "    for i in range(max_i + 1):      # i=0..max_i, i+1까지 접근\n",
    "        if is_neg_one(last[i]) and is_pos_one(last[i + 1]):\n",
    "            idx = i\n",
    "            break\n",
    "\n",
    "    if idx is None:\n",
    "        out[k] = traj.astype(np.float32)\n",
    "    else:\n",
    "        trimmed = traj[idx + 1 :].astype(np.float32)  # i보다 작은 step 삭제\n",
    "        removed_total += (idx + 1)\n",
    "        changed += 1\n",
    "        out[k] = trimmed\n",
    "\n",
    "print(f\"episodes: {len(data.files)}\")\n",
    "print(f\"trimmed episodes: {changed}\")\n",
    "print(f\"total removed timesteps: {removed_total}\")\n",
    "\n",
    "np.savez_compressed(out_path, **out)\n",
    "print(f\"saved -> {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "75820eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base episodes: 1462\n",
      "extra episodes: 195\n",
      "merged episodes: 1657\n",
      "saved -> merged_success_episodes.npz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "base_path  = \"all_success_episodes_trimmed.npz\"   # 약 1400개\n",
    "extra_path = \"dataset_all_afterpregrasp_t3.npz\"         # 약 200개\n",
    "out_path   = \"merged_success_episodes.npz\"\n",
    "\n",
    "# load\n",
    "base  = np.load(base_path, allow_pickle=True)\n",
    "extra = np.load(extra_path, allow_pickle=True)\n",
    "\n",
    "merged = {}\n",
    "# 1. base 그대로\n",
    "for k in base.files:\n",
    "    merged[k] = base[k]\n",
    "\n",
    "# 2. extra → 번호 새로 매기기\n",
    "start_idx = len(base.files)  # 예: 1400\n",
    "for i, k in enumerate(extra.files, start=1):\n",
    "    new_idx = start_idx + i  # 1401부터 시작\n",
    "    new_key = f\"episode{new_idx:04d}\"\n",
    "    merged[new_key] = extra[k]\n",
    "\n",
    "print(\"base episodes:\", len(base.files))\n",
    "print(\"extra episodes:\", len(extra.files))\n",
    "print(\"merged episodes:\", len(merged))\n",
    "\n",
    "# save\n",
    "np.savez_compressed(out_path, **merged)\n",
    "print(f\"saved -> {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eb9192c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 에피소드 수: 1657\n",
      "최소/중간/최대 길이: 62 301 367\n",
      "300 미만 에피소드 수: 2\n",
      "episode0006 63\n",
      "episode0007 62\n",
      "저장: short_episodes_lt300.txt\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "path = \"merged_success_episodes.npz\"  # 확인할 파일 경로\n",
    "data = np.load(path, allow_pickle=True)\n",
    "\n",
    "short_keys = []\n",
    "lengths = {}\n",
    "\n",
    "for k in data.files:\n",
    "    T = data[k].shape[0]\n",
    "    lengths[k] = T\n",
    "    if T < 200:\n",
    "        short_keys.append(k)\n",
    "\n",
    "print(\"총 에피소드 수:\", len(data.files))\n",
    "print(\"최소/중간/최대 길이:\",\n",
    "      min(lengths.values()), \n",
    "      int(np.median(list(lengths.values()))), \n",
    "      max(lengths.values()))\n",
    "print(\"300 미만 에피소드 수:\", len(short_keys))\n",
    "\n",
    "# 목록 출력\n",
    "for k in short_keys:\n",
    "    print(k, lengths[k])\n",
    "\n",
    "# 필요하면 파일로 저장\n",
    "with open(\"short_episodes_lt300.txt\", \"w\") as f:\n",
    "    for k in short_keys:\n",
    "        f.write(f\"{k}\\t{lengths[k]}\\n\")\n",
    "print(\"저장: short_episodes_lt300.txt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
